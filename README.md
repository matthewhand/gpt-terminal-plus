# GPT Terminal Plus

GPT Terminal Plus provides a secure and isolated environment where system CLI utilities can be accessed via HTTP endpoints. These endpoints allow chatbots, such as custom GPT models, to execute commands and retrieve results, ensuring strong isolation and security.

## Purpose

The primary purpose of GPT Terminal Plus is to grant access to system CLI utilities through HTTP endpoints, enabling chatbots to interact with and execute commands on various system tools. This approach ensures:
- **Isolation and Security**: Each tool runs in its own container, providing strong isolation and reducing the risk of one compromised tool affecting others. Containerization limits the potential attack surface for each tool.
- **Resource Management**: Docker allows setting resource limits for each container, ensuring one tool doesn't consume excessive resources, preventing denial-of-service scenarios caused by resource exhaustion.
- **Scalability**: Docker containers are lightweight and can be easily scaled up or down based on demand, allowing for efficient resource utilization and potential cost savings in cloud environments.

## Advanced Setup

For more advanced setup options, such as using Docker or deploying to Fly.io, refer to the following documentation:

- [Docker Setup](docs/DOCKER_SETUP.md)
- [Fly.io Deployment](docs/FLY_IO_DEPLOYMENT.md)
- [Configuration Details](docs/CONFIGURATION.md)

## Configuration

### Environment Variables

- **NODE_ENV**: Specifies the environment in which the application is running. Default is `development`.
- **DEBUG**: Enables debug logging.
- **API_TOKEN**: Token used for API authentication. This token must be generated by the user to secure their endpoint authentication at the application level. Users are free to use reverse proxy solutions like nginx for additional security.
- **NODE_CONFIG_DIR**: Directory for persisting `globalState.json` and server configurations.

## Contribution

Contributions are welcome for CLI software that follows a similar architecture. Each tool should have an exposed HTTP endpoint for ChatGPT custom GPT to access.

- **Examples**: Refer to the `docker/` directory for customized Docker container examples.
- **Deployment**: Refer to `.github/workflows/` for CI/CD setup and `fly_configs/` for deployment examples on Fly.io.

## Supporting Scripts

We provide supporting scripts in the `scripts/` directory. These scripts can configure nginx and Let's Encrypt to forward a given domain name into the container itself. This allows for secure reverse proxy setup.

For example:
```sh
# Run the script with your domain name
bash scripts/setup_nginx_letsencrypt.sh your-domain.com
```

For more detailed information, refer to the [documentation](docs).
